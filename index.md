---
layout: default
title: Explainable & Privacy-Preserving Misbehavior Detection in Next-Generation Vehicular Networks
---

# Explainable & Privacy-Preserving Misbehavior Detection in Next-Generation Vehicular Networks

## Format
**Half-day workshop** (4 hours total, including a Â½-hour refreshments break)

## Organizers

### Dr. Sohan Gyawali  
Assistant Professor, Department of Technology Systems  
East Carolina University  
East 5th Street Greenville, NC 27858 USA  
ðŸ“§ [gyawalis22@ecu.edu](mailto:gyawalis22@ecu.edu)  
ðŸ“ž 252-328-9692  
ðŸ”— [Website](https://cet.ecu.edu/techsystems/about-us/faculty-and-staff/gyawali_sohan/)

---

### Dr. Jiaqi Huang  
Department of Computer Science and Cybersecurity  
University of Central Missouri  
116 W South St, Warrensburg, MO 64093  
ðŸ“§ [jhuang@ucmo.edu](mailto:jhuang@ucmo.edu)  
ðŸ“ž 660-543-8865  
ðŸ”— [Website](https://www.ucmo.edu/college-of-health-science-and-technology/department-of-computer-science-and-cybersecurity/cybersecurity/faculty/dr-jiaqi-huang/index.php)

---

## Abstract

Vehicular communication networks enable intelligent transportation systems (ITS) by exchanging Basic Safety Messages (BSMs) to improve safety and traffic flow. Yet they remain vulnerable to attacksâ€”such as denial-of-service, Sybil, false alerts, and insider misbehaviorâ€”that traditional cryptographic defenses cannot fully mitigate.

This tutorial presents a unified framework for machine learningâ€“based misbehavior detection (MDS) in next-generation vehicular environments, emphasizing realistic data, privacy, and trust.

We begin with simulation-driven MDS trained on combined local perception and BSM datasets, showcasing its superiority over beacon-only methods. We then explore privacy-preserving techniques: homomorphic aggregation of encrypted feedback for reputation updates without revealing identity or location, and semi-supervised federated learning to train models collaboratively without raw data sharing.

Finally, we address transparency by integrating Explainable AI (XAI) with Large Language Models (LLMs). SHAP values quantify feature contributions, and an LLM uses these insightsâ€”plus vector-database contextsâ€”to generate clear, natural-language explanations. This empowers non-expert stakeholders (e.g., network operators, regulators) to understand and trust detection outcomes.

Attendees will leave equipped to design, implement, and evaluate secure, privacy-aware, and explainable MDS solutions for next-generation vehicular networks.

---

## Keywords

- Connected Vehicles  
- Misbehavior Detection  
- Machine Learning  
- Privacy-Preserving Techniques  
- Semi-Supervised Learning  
- Federated Learning  
- SHAP  
- LLMs  

---

## Tentative Session Program

| Time        | Session Description                              |
|-------------|---------------------------------------------------|
| 09:00â€“10:30 | **Session 1:** Foundations of MDS and Realistic Data Modeling |
| 10:30â€“11:00 | **Break** (Refreshments)                          |
| 11:00â€“12:00 | **Session 2:** Privacy-Preserving MDS: FL + Encryption |
| 12:00â€“13:00 | **Session 3:** Explainability with SHAP + LLMs    |

---

